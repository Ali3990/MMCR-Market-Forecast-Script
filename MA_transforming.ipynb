{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f74d8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "from Moodys_API_script.Moodys_API import download_basket\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "acckey=str(os.getenv(\"acc_key\"))\n",
    "enckey=str(os.getenv(\"enc_key\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dccadc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basket ID: E3BCC362-65B1-4970-9E5D-4407D4E28831\n",
      "Basket Name: TM Forecast - Data Buffet\n",
      "Order ID: E553D4B9-B733-4D8B-A53E-5EF5294389C9\n",
      "Successful Order! Status Code: 200\n"
     ]
    }
   ],
   "source": [
    "# See api script for instructions on setting variables\n",
    "BASKET_NAME = \"TM Forecast - Data Buffet\"\n",
    "target_dir = r'C:\\Users\\ALi\\OneDrive - MMC\\Desktop\\MMCR\\Apt Forecasts\\Forecast process 2025\\Data\\MA Forecast Data'\n",
    "filename = BASKET_NAME + \".xlsx\"\n",
    "\n",
    "df = download_basket(BASKET_NAME, target_dir, filename, acckey, enckey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05bcbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary to transform the dataset:\n",
    "df = pd.read_excel(r'C:\\Users\\ALi\\OneDrive - MMC\\Desktop\\MMCR\\Apt Forecasts\\Forecast process 2025\\Data\\MA Forecast Data\\TM Forecast - Data Buffet.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14557020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved US Metro Total to directory.\n",
      "Saved Denver to directory.\n",
      "Saved Los Angeles to directory.\n",
      "Saved Oakland-East Bay to directory.\n",
      "Saved Orange County to directory.\n",
      "Saved Portland to directory.\n",
      "Saved San Jose to directory.\n",
      "Saved San Diego to directory.\n",
      "Saved Ventura County to directory.\n",
      "Saved Fairfield County to directory.\n",
      "Saved Boston to directory.\n",
      "Saved New York Metro to directory.\n",
      "Saved Northern New Jersey to directory.\n",
      "Saved Long Island to directory.\n",
      "Saved District of Columbia to directory.\n",
      "Saved Atlanta to directory.\n",
      "Saved Austin to directory.\n",
      "Saved Central New Jersey to directory.\n",
      "Saved Charleston to directory.\n",
      "Saved Charlotte to directory.\n",
      "Saved Dallas to directory.\n",
      "Saved Fort Lauderdale to directory.\n",
      "Saved Fort Worth to directory.\n",
      "Saved Miami to directory.\n",
      "Saved Orlando to directory.\n",
      "Saved San Bernardino-Riverside to directory.\n",
      "Saved Tampa-St. Petersburg to directory.\n",
      "Saved Seattle 1 to directory.\n",
      "Saved Seattle 2 to directory.\n",
      "Saved San Francisco 1 to directory.\n",
      "Saved San Francisco 2 to directory.\n",
      "Saved Raleigh-Durham 1 to directory.\n",
      "Saved Raleigh-Durham 2 to directory.\n"
     ]
    }
   ],
   "source": [
    "# See Mnemonic_compiler.xlsx file >> 'Dict' for dictionary compiler. Add more markets as necessary. Paste the entire dictionary here.\n",
    "# e.g. 'market': ['MMC abbreviation', 'REIS abbreviation', 'geocode']\n",
    "tm_dict = {\n",
    "    'US Metro Total': ['US', 'US', 'IUSA'],\n",
    "    'Denver':  ['DEN',  'DE',  'IUSA_MDEN'],\n",
    "    'Los Angeles':  ['LA',  'LA',  'IUSA_DMLOS'],\n",
    "    'Oakland-East Bay':  ['OAK',  'OA',  'IUSA_DMOAK'],\n",
    "    'Orange County':  ['OC',  'OC',  'IUSA_DMANA'],\n",
    "    'Portland':  ['POR',  'PO',  'IUSA_MPOT'],\n",
    "    'San Jose':  ['SJ',  'SJ',  'IUSA_MSAJ'],\n",
    "    'San Diego':  ['SD',  'SD',  'IUSA_MSAN'],\n",
    "    'Ventura County':  ['VC',  'VN',  'IUSA_MOXN'],\n",
    "    'Fairfield County':  ['FC',  'FC',  'IUSA_MBSD'],\n",
    "    'Boston':  ['BOS',  'BO',  'IUSA_MBOS'],\n",
    "    'New York Metro':  ['NYM',  'NY',  'IUSA_DMNWY'],\n",
    "    'Northern New Jersey':  ['NNJ',  'NJ',  'IUSA_DMNEK'],\n",
    "    'Long Island':  ['LI',  'LI',  'IUSA_DMNAS'],\n",
    "    'District of Columbia':  ['DC',  'DC',  'IUSA_MWAA'],\n",
    "    'Atlanta':  ['ATL',  'AT',  'IUSA_MATS'],\n",
    "    'Austin':  ['AUS',  'AU',  'IUSA_MAUS'],\n",
    "    'Central New Jersey':  ['CNJ',  'CJ',  'IUSA_DMLNB'],\n",
    "    'Charleston':  ['CHS',  'CN',  'IUSA_MCHS'],\n",
    "    'Charlotte':  ['CHR',  'CR',  'IUSA_MCLT'],\n",
    "    'Dallas':  ['DAL',  'DA',  'IUSA_DMDAL'],\n",
    "    'Fort Lauderdale':  ['FL',  'FL',  'IUSA_DMFOT'],\n",
    "    'Fort Worth':  ['FW',  'FW',  'IUSA_DMDLL'],\n",
    "    'Miami':  ['MIA',  'MI',  'IUSA_DMMIA'],\n",
    "    'Orlando':  ['ORL',  'OR',  'IUSA_MORL'],\n",
    "    'San Bernardino-Riverside':  ['SB',  'SB',  'IUSA_MRIV'],\n",
    "    'Tampa-St. Petersburg':  ['TAM',  'TA',  'IUSA_MTAM'],\n",
    "    'US Metro Total':  ['US',  'US',  'IUSA'],\n",
    "    'Seattle 1':  ['SEA',  'SE',  'IUSA_DMEVE'],\n",
    "    'Seattle 2':  ['EVE',  'SE',  'IUSA_DMSEB'],\n",
    "    'San Francisco 1':  ['SF',  'SF',  'IUSA_DMSAF'],\n",
    "    'San Francisco 2':  ['SR',  'SF',  'IUSA_DMSRF'],\n",
    "    'Raleigh-Durham 1':  ['RAL',  'RD',  'IUSA_MRAL'],\n",
    "    'Raleigh-Durham 2':  ['DUR',  'RD',  'IUSA_MDUR']\n",
    "}\n",
    "\n",
    "output_dir = r'C:\\Users\\ALi\\OneDrive - MMC\\Desktop\\MMCR\\Apt Forecasts\\Forecast process 2025\\Data\\MA Forecast Data'\n",
    "\n",
    "\n",
    "for market, values in tm_dict.items():\n",
    "    #grabs 3rd element in tm_dict\n",
    "    geocode = values[2] \n",
    "\n",
    "    # create list of exact geocode matches in column headers\n",
    "    matching_cols = [col for col in df.columns if geocode in col]\n",
    "\n",
    "    if not matching_cols:\n",
    "        continue # handle the columns by skipping over ones that do not have matching geocode.\n",
    "    \n",
    "    # temp df to retain the first index column with dates, then filter and join the matching columns\n",
    "    sub_df = df.iloc[:, [0]].join(df[matching_cols]) \n",
    "\n",
    "    file_path = os.path.join(output_dir, f\"{market}.xlsx\")\n",
    "    sub_df.to_excel(file_path, index=False)\n",
    "\n",
    "    print(f\"Saved {market} to directory.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyDashVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
